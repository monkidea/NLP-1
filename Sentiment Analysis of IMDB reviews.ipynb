{
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "name": "python", 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "source": "import numpy\nfrom keras.datasets import imdb\nfrom matplotlib import pyplot\n# load the dataset\n(X_train, y_train), (X_test, y_test) = imdb.load_data()\nX = numpy.concatenate((X_train, X_test), axis=0)\ny = numpy.concatenate((y_train, y_test), axis=0)", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }, 
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n17457152/17464789 [============================>.] - ETA: 0s"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 2, 
            "cell_type": "code", 
            "source": "\nprint(X.shape)\nprint(y.shape)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "(50000,)\n(50000,)\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 3, 
            "cell_type": "code", 
            "source": "print(numpy.unique(y))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "[0 1]\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 4, 
            "cell_type": "code", 
            "source": "print(len(numpy.unique(numpy.hstack(X))))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "88585\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 6, 
            "cell_type": "code", 
            "source": "#print(len(numpy.unique(numpy.vstack(X))))\n#hstack due to axis mismatch", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 7, 
            "cell_type": "code", 
            "source": "# Summarize review length\nprint(\"Review length: \")\nresult = map(len, X)\nprint(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n# plot review length as a boxplot and histogram\npyplot.subplot(121)\npyplot.boxplot(result)\npyplot.subplot(122)\npyplot.hist(result)\npyplot.show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Review length: \nMean 234.76 words (172.911495)\n"
                }, 
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<matplotlib.figure.Figure at 0x7f98fd12ea50>", 
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"
                    }, 
                    "output_type": "display_data"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "source": "# MLP for the IMDB problem\nimport numpy\nfrom keras.datasets import imdb\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 10, 
            "cell_type": "code", 
            "source": "# load the dataset but only keep the top n words, zero the rest\ntop_words = 5000\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 19, 
            "cell_type": "code", 
            "source": "X_train[0:22,0:20]", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [ 687,   23,    4,    2,    2,    6, 3693,   42,   38,   39,  121,\n          59,  456,   10,   10,    7,  265,   12,  575,  111],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   4, 3231,  152,  339,    2,   42, 4869,    2,    2,  345, 4804,\n           2,  142,   43,  218,  208,   54,   29,  853,  659],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [  16,    4,    2,    2,  678, 1701,    4,  530,    2, 3770,   37,\n           2,   98,   32,   17,    2,   27, 4185,   33,   24],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
                    }, 
                    "execution_count": 19, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 11, 
            "cell_type": "code", 
            "source": "max_words = 500\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)\n\n# restrict reviews to 500 owrds.. longer ones are truncated ..shorter ones padded..", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 12, 
            "cell_type": "code", 
            "source": "# create the model\nmodel = Sequential()\nmodel.add(Embedding(top_words, 32, input_length=max_words)) #Embedding\n#Turns positive integers (indexes) into dense vectors of fixed size\nmodel.add(Flatten())\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 500, 32)           160000    \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 16000)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 250)               4000250   \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 251       \n=================================================================\nTotal params: 4,160,501\nTrainable params: 4,160,501\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 13, 
            "cell_type": "code", 
            "source": "# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128,verbose=1)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/2\n25000/25000 [==============================] - 42s - loss: 0.5206 - acc: 0.7051 - val_loss: 0.2974 - val_acc: 0.8722\nEpoch 2/2\n25000/25000 [==============================] - 41s - loss: 0.1936 - acc: 0.9240 - val_loss: 0.3187 - val_acc: 0.8675\n"
                }, 
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f98fd7159d0>"
                    }, 
                    "execution_count": 13, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 14, 
            "cell_type": "code", 
            "source": "# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Accuracy: 86.75%\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 15, 
            "cell_type": "code", 
            "source": "X_train.shape", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(25000, 500)"
                    }, 
                    "execution_count": 15, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 17, 
            "cell_type": "code", 
            "source": "X_train[0:2,0:20]", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
                    }, 
                    "execution_count": 17, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 20, 
            "cell_type": "code", 
            "source": "#1D CNN\n# 2D CNN would honor the spatial structure in image data while being robust to the position and orientation of learned objects in the scene.\n# same priciples run the 1D etc..", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 21, 
            "cell_type": "code", 
            "source": "from keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\n\n# create the model\nmodel = Sequential()\nmodel.add(Embedding(top_words, 32, input_length=max_words))\nmodel.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 500, 32)           160000    \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 500, 32)           3104      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 8000)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 250)               2000250   \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 251       \n=================================================================\nTotal params: 2,163,605\nTrainable params: 2,163,605\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 22, 
            "cell_type": "code", 
            "source": "# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128,verbose=2)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/2\n48s - loss: 0.4870 - acc: 0.7188 - val_loss: 0.2934 - val_acc: 0.8757\nEpoch 2/2\n48s - loss: 0.2359 - acc: 0.9059 - val_loss: 0.2941 - val_acc: 0.8771\n"
                }, 
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f98d411ef90>"
                    }, 
                    "execution_count": 22, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 23, 
            "cell_type": "code", 
            "source": "# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}