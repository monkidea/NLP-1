{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_seq2seq_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronykroy/NLP/blob/master/NLP_seq2seq_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FOwWSINgCxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ozhiN9gDke",
        "colab_type": "text"
      },
      "source": [
        "## They never really tell you how to clean the data do they...?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ri4O53w40wI",
        "colab_type": "code",
        "outputId": "2f9deefd-d5df-42bc-dba6-b171860351a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "! wget https://snap.stanford.edu/data/finefoods.txt.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-06 02:58:43--  https://snap.stanford.edu/data/finefoods.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122104202 (116M) [application/x-gzip]\n",
            "Saving to: ‘finefoods.txt.gz’\n",
            "\n",
            "finefoods.txt.gz    100%[===================>] 116.45M  35.6MB/s    in 4.0s    \n",
            "\n",
            "2019-11-06 02:58:47 (28.8 MB/s) - ‘finefoods.txt.gz’ saved [122104202/122104202]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcEldWa6L2j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gunzip finefoods.txt.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew9WznGQMIsw",
        "colab_type": "code",
        "outputId": "8c73c2b5-035f-46ad-8668-0dede0bac4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finefoods.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8PIDPJYM05B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('finefoods.txt', 'r',encoding = 'latin') as infile:\n",
        "    lines = [line for line in infile]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuCYHU4pYbyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwfOr8TP8i1",
        "colab_type": "code",
        "outputId": "d2cb3a92-79d5-4d6f-90a9-b97dd353dc64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5116093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfa2DA4RMLzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines_cleaned = [l.rstrip(\"\\n\\r\") for l in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx5NyIkrUM3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ind_start = [i for i, s in enumerate(lines_cleaned) if 'product/productId' in s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA9TcgheUcXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_end = [i for i, s in enumerate(lines_cleaned) if 'review/text' in s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbDlQOE4QBMM",
        "colab_type": "code",
        "outputId": "a85acc99-20fe-486c-8c94-f7ba9416a4be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(ind_start); ind_start[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 9, 18, 27, 36, 45, 54, 63, 72, 81]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdKZ689sSWXQ",
        "colab_type": "code",
        "outputId": "ba5a61af-c849-47ba-91aa-9b817a8b4f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(ind_end);ind_end[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 16, 25, 34, 43, 52, 61, 70, 79, 88]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyGwZ8EeQReY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a = zip(ind_start,ind_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBHR5IBuZifR",
        "colab_type": "code",
        "outputId": "8053760e-833e-49e3-bada-1dbe3de7c7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "pd_list=[]\n",
        "for i in range(len(ind_end)):\n",
        "  try:\n",
        "    dict_2={} # empty dict\n",
        "    c = lines_cleaned[ind_start[i]:ind_end[i]+1]\n",
        "    for entry in c:\n",
        "      d = entry.split(': ')\n",
        "      dict_2[d[0].split('/')[1]] = d[1]\n",
        "    \n",
        "    pd_list.append(dict_2)\n",
        "  except IndexError as index_error:\n",
        "    print('index error occurred for',c)\n",
        "    print('at entry',entry)\n",
        "    print('at index',ind_start[i])\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index error occurred for ['product/productId: B002RIZUQ2', 'review/userId: AS2DLXUWDK0GP', 'review/profileName: MABEL \"Tell us about yourself!', '88 years old. ...', 'review/helpfulness: 1/1', 'review/score: 4.0', 'review/time: 1289088000', 'review/summary: delicious', \"review/text: if you prefer a tasteful and less strong flavored coffee, I reommend Green Mountain's hazelnut.  I have not been a coffee drinker, but upon tasting this brew, I drink it daily.\"]\n",
            "at entry 88 years old. ...\n",
            "at index 847773\n",
            "index error occurred for ['product/productId: B004FEJ968', 'review/userId: ALDIU41MJLTZA', 'review/profileName: Don Snyder \"The Idea Guy', '...creative powers b...', 'review/helpfulness: 0/0', 'review/score: 3.0', 'review/time: 1308182400', 'review/summary: Less would have been more', \"review/text: The taste of the Newton's Fruit Thins was pretty good. It's a nice crunchy treat, and I really enjoyed the cranberry citrus and oat flavor. It was like a really thin and crisp designer oatmeal cookie.  I would have liked the product more if the cookies were smaller in size.  The snacks are rather large and round in shape, and being so thin they easily break and crumble. If they were 1/4 of the current size you could easily consume them in one or two bites and eliminate the crumbs.  The packaging leaves a lot to be desired. The outer foil bag isn't bad, but the inside plastic tray is clumsy and tough to slide back into the resealable wrap, and combined with the large crumbly nature of the cookie already mentioned above I doubt very much if anyone buying these in a store ends up with more than half of the cookies actually being whole by the time they get home.  Ordering them from Amazon easily guarantees half the product inside will be in pieces -- but like I said... the smaller size (even if they are broken pieces) makes 'em easier to eat!\"]\n",
            "at entry ...creative powers b...\n",
            "at index 1593766\n",
            "index error occurred for ['product/productId: B004APZYVG', 'review/userId: AAW9ZM7G78WAK', 'review/profileName: Sherry \"Tell us about yourself!', 'School Princi...', 'review/helpfulness: 0/0', 'review/score: 5.0', 'review/time: 1341360000', 'review/summary: Get Coffee Shop flavor at home', 'review/text: This mocha coffee is as good as any I have had at Starbucks or Dunkin Donuts at a fraction of the cost.<br />Treat yourself to a special flavored coffee experience at home anytime.  I like to add just a little skim milk to my mug and it is even smoother.  Try it you will like it.']\n",
            "at entry School Princi...\n",
            "at index 1711784\n",
            "index error occurred for ['product/productId: B004EE0TYK', 'review/userId: AAW9ZM7G78WAK', 'review/profileName: Sherry \"Tell us about yourself!', 'School Princi...', 'review/helpfulness: 0/0', 'review/score: 5.0', 'review/time: 1341360000', 'review/summary: Get Coffee Shop flavor at home', 'review/text: This mocha coffee is as good as any I have had at Starbucks or Dunkin Donuts at a fraction of the cost.<br />Treat yourself to a special flavored coffee experience at home anytime.  I like to add just a little skim milk to my mug and it is even smoother.  Try it you will like it.']\n",
            "at entry School Princi...\n",
            "at index 2554500\n",
            "index error occurred for ['product/productId: B003XBBAUM', 'review/userId: A2HVY3YRSJR5NF', 'review/profileName: J. Facey \"J.F., CA', 'I am a voracious reader/li...', 'review/helpfulness: 2/2', 'review/score: 5.0', 'review/time: 1332633600', 'review/summary: The absolute best - taste better than brown sugar', 'review/text: I recently bought this sugar alternative and I am completely blown away! I have fibromyalgia, multiple food allergies/sensitivities and so many thing make me feel bad including exacerbating my pain. This does not have any negative effects on me whatsoever. The taste is out of this world! I am tempted to just eat it. This one is a winner! A little secret - I found it much cheaper at Whole Foods market.']\n",
            "at entry I am a voracious reader/li...\n",
            "at index 3160642\n",
            "index error occurred for ['product/productId: B004M62COU', 'review/userId: AAW9ZM7G78WAK', 'review/profileName: Sherry \"Tell us about yourself!', 'School Princi...', 'review/helpfulness: 0/0', 'review/score: 5.0', 'review/time: 1341360000', 'review/summary: Tasty, smooth, with full flavor', 'review/text: This coffee blend is full bodied but not overpowering and makes for a smooth tasty cup of coffee.  It is great anytime of day.  Green Mountain has done an excellent job with this blend.  You will not be disappointed.']\n",
            "at entry School Princi...\n",
            "at index 3396182\n",
            "index error occurred for ['product/productId: B0061IUIDY', 'review/userId: ALDIU41MJLTZA', 'review/profileName: Don Snyder \"The Idea Guy', '...creative powers b...', 'review/helpfulness: 1/2', 'review/score: 2.0', 'review/time: 1343260800', 'review/summary: There are better brands out there', 'review/text: I\\'m a huge fan of tea and drink a LOT of it.  This is the first time I tried Higgins & Burke brand and have to say that I\\'ve never heard of it before.  English Breakfast Tea is probably my second favorite packaged tea to drink (Earl Grey being my first choice), but most brands I\\'ve tried are usually pretty similar.  Not so with this brand.  The aroma didn\\'t seem as rich and flavor seemed somehow \"off\" to me, but I couldn\\'t quite put my finger on what I didn\\'t like until I read one of the other reviews here on Amazon and the reviewer described it as \"musky.\"  That\\'s about as accurate a description as I can think of.<br /><br />I like my tea strong (leaving the bag to steep the entire time I\\'m drinking it) and do not add sweetener or cream or lemon.  After trying the first cup, I knew that I\\'d have to add something so on my second mug I added a bit of sweetener and it helped take the musky edge off, but it still wasn\\'t what I consider a flavorful English Breakfast blend.<br /><br />If you\\'re a fan of traditional English Breakfast Tea I would recommend <a href=\"http://www.amazon.com/gp/product/B000F4F952\">Twinings English Breakfast Tea, Tea Bags, 50-Count Boxes (Pack of 6)</a>, <a href=\"http://www.amazon.com/gp/product/B0010DLWT4\">The Republic of Tea, British Breakfast Tea, 50-Count</a>, or even <a href=\"http://www.amazon.com/gp/product/B0000C69FB\">Tazo Awake Black Tea, 24-Count Tea Bags (Pack of 6)</a> over the Higgins & Burke brand.']\n",
            "at entry ...creative powers b...\n",
            "at index 4845255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlBcgiRZfj8L",
        "colab_type": "code",
        "outputId": "91376dea-27b6-4017-b4d5-17d9b30bfc05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(ind_end)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPMsjXg9duSP",
        "colab_type": "code",
        "outputId": "66869527-8c5f-4ac5-f77e-e0b5c0b3bdb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(pd_list) # close enuf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKjzVP19fph4",
        "colab_type": "code",
        "outputId": "af00e71e-d599-4a9f-b656-7028fe1ac6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(ind_end) -len(pd_list) # exactly the number of times the index eror popped up"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co8Jxy39fQDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd_list[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SNab3WtWi9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(pd_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vCQ7F9TL-hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5eVxE2gliP",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55thQYckgo6Y",
        "colab_type": "code",
        "outputId": "39934670-86a4-486d-d28c-d6a312507e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['productId', 'userId', 'profileName', 'helpfulness', 'score', 'time',\n",
              "       'summary', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSUGKN-wNyXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop_duplicates(subset=['text'],inplace=True)  #dropping duplicates\n",
        "df.dropna(axis=0,inplace=True)   #dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia2QYZXjhHBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a patently ridiculoud pre processing step "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAIstgguN0TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                            \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                            \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                            \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                            \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                            \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                            \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                            \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                            \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                            \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                            \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                            \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                            \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                            \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                            \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                            \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                            \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                            \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                            \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                            \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                            \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                            \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                            \"you're\": \"you are\", \"you've\": \"you have\"} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8qF4jlShKBO",
        "colab_type": "code",
        "outputId": "0f43c9f1-1b2b-45b5-ea69-ebadede5caa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df['text'][:2]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I have bought several of the Vitality canned d...\n",
              "1    Product arrived labeled as Jumbo Salted Peanut...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYWoTrROheCr",
        "colab_type": "text"
      },
      "source": [
        "## I can has the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjPbbWgJhZ0M",
        "colab_type": "code",
        "outputId": "a889a9d9-2778-41a2-bae1-77cb3289e187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x \n",
        "# enforce 2.x compliance anyway"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU07ZaZ4hYED",
        "colab_type": "code",
        "outputId": "adf0803f-d0d1-44a0-8d9b-c918237dfe76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\") \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GncnkEHh6wi",
        "colab_type": "code",
        "outputId": "5501dc02-f5f4-4511-99bf-e68228fb3b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwtNd5BGhOSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text # there were links in the original data seth that might have been a ready made .csv file..?\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in df['text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNMS4_E-hR2f",
        "colab_type": "code",
        "outputId": "e2b64b27-ba42-4f00-eb3c-3b495e4c964f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df['summary'][:2]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Good Quality Dog Food\n",
              "1        Not as Advertised\n",
              "Name: summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mElP33dtiVzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in df['summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_I22cmsjAu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned_text']=cleaned_text\n",
        "df['cleaned_summary']=cleaned_summary\n",
        "df['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "df.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTrs_4oujBfA",
        "colab_type": "code",
        "outputId": "c195f9c2-b427-47a1-cf08-ef424faa9779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productId</th>\n",
              "      <th>userId</th>\n",
              "      <th>profileName</th>\n",
              "      <th>helpfulness</th>\n",
              "      <th>score</th>\n",
              "      <th>time</th>\n",
              "      <th>summary</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1/1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
              "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0/0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
              "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
              "      <td>not as advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1/1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
              "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
              "      <td>delight says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3/3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
              "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0/0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
              "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    productId  ...         cleaned_summary\n",
              "0  B001E4KFG0  ...  good quality dog food \n",
              "1  B00813GRG4  ...      not as advertised \n",
              "2  B000LQOCH0  ...    delight says it all \n",
              "3  B000UA0QIQ  ...         cough medicine \n",
              "4  B006K2ZZ7K  ...            great taffy \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mCwktymjGDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned_summary'] = df['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
        "# spl tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixry13ArjOJz",
        "colab_type": "code",
        "outputId": "fd1e8ff8-b367-4909-e40e-75f861e07895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"Review:\",df['cleaned_text'][i])\n",
        "    print(\"Summary:\",df['cleaned_summary'][i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Summary: _START_ good quality dog food  _END_\n",
            "\n",
            "\n",
            "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Summary: _START_ not as advertised  _END_\n",
            "\n",
            "\n",
            "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Summary: _START_ delight says it all  _END_\n",
            "\n",
            "\n",
            "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
            "Summary: _START_ cough medicine  _END_\n",
            "\n",
            "\n",
            "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Summary: _START_ great taffy  _END_\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlV1syTijT9X",
        "colab_type": "code",
        "outputId": "cb59c79a-765a-4cac-de65-9d414fb5ba4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df[['cleaned_text','cleaned_summary']].head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
              "      <td>_START_ good quality dog food  _END_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
              "      <td>_START_ not as advertised  _END_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
              "      <td>_START_ delight says it all  _END_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
              "      <td>_START_ cough medicine  _END_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
              "      <td>_START_ great taffy  _END_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                              cleaned_text                       cleaned_summary\n",
              "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better  _START_ good quality dog food  _END_\n",
              "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo      _START_ not as advertised  _END_\n",
              "2  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...    _START_ delight says it all  _END_\n",
              "3                                                                              looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal         _START_ cough medicine  _END_\n",
              "4                                                                                                                      great taffy great price wide assortment yummy taffy delivery quick taffy lover deal            _START_ great taffy  _END_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y52zoNOljctt",
        "colab_type": "code",
        "outputId": "0e8b23e2-d672-46e9-c32d-8ccbf31ba692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in df['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 10)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEICAYAAABBBrPDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngcLMzAo5UJiZWSEHCjMzK/T/AeBRSRlFIEHxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tV9xFa1j4iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summary : limit it to 10 there is a drop at 10 check histogram\n",
        "# text 125 is ok...\n",
        "max_len_text=125 \n",
        "max_len_summary=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwJD14YdkWgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(df['cleaned_text'],df['cleaned_summary'],test_size=0.1,random_state=0,shuffle=True) \n",
        "# train is the cleaned text, val is the cleaned summary\n",
        "# *args\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w8X3VDekn8p",
        "colab_type": "text"
      },
      "source": [
        "## NLP part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMWHUJEFkzOg",
        "colab_type": "code",
        "outputId": "6d1d6fee-6b99-428b-d502-710a80b07ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "pd.DataFrame(x_tr).head() # just a dekko"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>386865</th>\n",
              "      <td>tea exactly wanted rich warm spicy cinnamon tea tea well packaged cannot even smell tea bag without opening foil pouches means keeping tea fresh brewed tea hot milk also nice cinnamon milk tea per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334183</th>\n",
              "      <td>bought case costco crackers cheese good every single package crackers cheese cheese missing rip like filled completely save cheese pay something expect product full air never buy product understand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302448</th>\n",
              "      <td>tea tea brand pre made tea found enjoy drink white jasmine oolong varieties glad amazon offers free shipping tea expensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143695</th>\n",
              "      <td>kraft macaroni cheese beckons back lonely days running home lunchtime lay heart strewn crying harsh rejection meted upon fairest playground beauties soft noodles cheese cream sauce would ease ache...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120805</th>\n",
              "      <td>way sweet taste like hot sugar water coffee back ground taste sorry bought nothing like get coffe shop waste money</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                   cleaned_text\n",
              "386865  tea exactly wanted rich warm spicy cinnamon tea tea well packaged cannot even smell tea bag without opening foil pouches means keeping tea fresh brewed tea hot milk also nice cinnamon milk tea per...\n",
              "334183    bought case costco crackers cheese good every single package crackers cheese cheese missing rip like filled completely save cheese pay something expect product full air never buy product understand\n",
              "302448                                                                               tea tea brand pre made tea found enjoy drink white jasmine oolong varieties glad amazon offers free shipping tea expensive\n",
              "143695  kraft macaroni cheese beckons back lonely days running home lunchtime lay heart strewn crying harsh rejection meted upon fairest playground beauties soft noodles cheese cream sauce would ease ache...\n",
              "120805                                                                                       way sweet taste like hot sugar water coffee back ground taste sorry bought nothing like get coffe shop waste money"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5avb_Usgkjhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data # see we avoid using it on the \n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO2b6eimlDH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTX4yXiWlE--",
        "colab_type": "code",
        "outputId": "6afca41d-e060-4418-da30-fb064a7fd25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_voc_size, x_voc_size)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30963 108950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC7LSDfloC8O",
        "colab_type": "text"
      },
      "source": [
        "## the Attention layer\n",
        "https://github.com/thushv89/attention_keras/blob/master/layers/attention.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq7VvgQQoCb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPFJuZvVmif7",
        "colab_type": "text"
      },
      "source": [
        "## Model building\n",
        "\n",
        "\n",
        "1. Return Sequences = LSTM produces the hidden state and cell state for every timestep\n",
        "2. Return State = True: LSTM produces the hidden state and cell state of the last timestep only\n",
        "3. Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "3. Stacked LSTM: Stacked LSTM has multiple layers of LSTM modules stacked on top of each other. This leads to a better representation of the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_-sd1eHmdld",
        "colab_type": "code",
        "outputId": "030127d5-bcfe-474c-ed0d-a241d62f0bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "from keras import backend as K \n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 125)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 125, 500)     54475000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 125, 500), ( 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 125, 500), ( 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    15481500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 125, 500), ( 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 30963)  30993963    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 109,458,963\n",
            "Trainable params: 109,458,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjFbmF0GnImA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "# remember sparse categorical entropy from bert for news groups\n",
        "# takes care of the 1 hot encoding thing on the fly.. then as now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyTokx8Towlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) # check the equivalent in the lr finder in fastai docs :)\n",
        "# stops when val loss increases.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEE3mazkpyJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.DataFrame(x_tr).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8NYOl0BpBVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.DataFrame(y_tr).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Rr-9TUuONB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do we need a warm up here..? https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=IVxrG3Osa1tM\n",
        "# https://stackoverflow.com/questions/45063489/first-tf-session-run-performs-dramatically-different-from-later-runs-why/45067900#45067900\n",
        "# port to a tPU.. with a ridiculous batch size 2048..?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPEId0z8o1Yy",
        "colab_type": "code",
        "outputId": "92f957e5-b9aa-438c-8b3a-0ef5211def21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "history = model.fit( [x_tr,y_tr[:,:-1]], # x concatenated to y's all but last column is the input\n",
        "                  y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] , # output > y all columns barring the first\n",
        "                  epochs=12, # was 50 ; an ungodly number\n",
        "                  callbacks=[es],\n",
        "                  batch_size=512, \n",
        "                  validation_data=([x_val,y_val[:,:-1]], # somewhat akin to ... given all this.. predict all of y and th last time step of y\n",
        "                                   y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:])) # the last time step of y wasn't included in the input data"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 353122 samples, validate on 39236 samples\n",
            "Epoch 1/12\n",
            "353122/353122 [==============================] - 2420s 7ms/sample - loss: 2.7288 - val_loss: 2.3258\n",
            "Epoch 2/12\n",
            "353122/353122 [==============================] - 2408s 7ms/sample - loss: 2.2316 - val_loss: 2.1209\n",
            "Epoch 3/12\n",
            "353122/353122 [==============================] - 2406s 7ms/sample - loss: 2.0706 - val_loss: 2.0405\n",
            "Epoch 4/12\n",
            "353122/353122 [==============================] - 2401s 7ms/sample - loss: 1.9709 - val_loss: 1.9987\n",
            "Epoch 5/12\n",
            "353122/353122 [==============================] - 2401s 7ms/sample - loss: 1.8933 - val_loss: 1.9793\n",
            "Epoch 6/12\n",
            "353122/353122 [==============================] - 2406s 7ms/sample - loss: 1.8257 - val_loss: 1.9743\n",
            "Epoch 7/12\n",
            "353122/353122 [==============================] - 2404s 7ms/sample - loss: 1.7638 - val_loss: 1.9708\n",
            "Epoch 8/12\n",
            "353122/353122 [==============================] - 2400s 7ms/sample - loss: 1.7048 - val_loss: 1.9762\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51wJfv-rvAJe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQf4-RyrqCFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}