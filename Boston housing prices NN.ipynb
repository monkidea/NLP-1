{
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "name": "python", 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "source": "!rm -f housing.csv\n!wget https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data -O housing.csv", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "--2018-02-02 05:14:07--  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 49082 (48K) [text/plain]\nSaving to: \u2018housing.csv\u2019\n\n100%[======================================>] 49,082      --.-K/s   in 0.07s   \n\n2018-02-02 05:14:07 (729 KB/s) - \u2018housing.csv\u2019 saved [49082/49082]\n\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 2, 
            "cell_type": "code", 
            "source": "import numpy\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 3, 
            "cell_type": "code", 
            "source": "# load dataset\ndataframe = read_csv(\"housing.csv\", delim_whitespace=True, header=None)\ndataset = dataframe.values\n# split into input and output variables\nX = dataset[:,0:13]\nY = dataset[:,13]", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 4, 
            "cell_type": "code", 
            "source": "# define base model\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 5, 
            "cell_type": "code", 
            "source": "# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 6, 
            "cell_type": "code", 
            "source": "# evaluate model\nestimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 7, 
            "cell_type": "code", 
            "source": "kfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(estimator, X, Y, cv=kfold)\nprint(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Baseline: 31.27 (23.87) MSE\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "source": "estimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5,verbose=0)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)\n# Standardization of inputs..", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 10, 
            "cell_type": "code", 
            "source": "results = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Standardized: 29.79 (26.40) MSE\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "# Tuning the n/w it self\n# present :: 13 inputs -> [13 -> 6] -> 1 output", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 13, 
            "cell_type": "code", 
            "source": "# define the model\ndef larger_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 14, 
            "cell_type": "code", 
            "source": "# evaluate model with standardized dataset\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5,\nverbose=0)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 15, 
            "cell_type": "code", 
            "source": "results = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Larger: 23.09 (26.78) MSE\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": 16, 
            "cell_type": "code", 
            "source": "def wider_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 17, 
            "cell_type": "code", 
            "source": "# evaluate model with standardized dataset\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5,\nverbose=0)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "execution_count": 18, 
            "cell_type": "code", 
            "source": "results = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Wider: 22.96 (26.29) MSE\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}